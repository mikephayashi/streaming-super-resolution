w{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgVHDihdjRzK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from math import sqrt\n",
    "from functools import partial, lru_cache\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uB8E-hojkKMW"
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channel, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channel, channel, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel, in_channel, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        out += input\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYLf-xrWkQ6j"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channel, channel, n_res_block, n_res_channel, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        if stride == 4:\n",
    "            blocks = [\n",
    "                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 2, channel, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel, channel, 3, padding=1),\n",
    "            ]\n",
    "\n",
    "        elif stride == 2:\n",
    "            blocks = [\n",
    "                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 2, channel, 3, padding=1),\n",
    "            ]\n",
    "\n",
    "        for i in range(n_res_block):\n",
    "            blocks.append(ResBlock(channel, n_res_channel))\n",
    "\n",
    "        blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.blocks(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlEIYue-kS0f"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channel, out_channel, channel, n_res_block, n_res_channel, stride\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        blocks = [nn.Conv2d(in_channel, channel, 3, padding=1)]\n",
    "\n",
    "        for i in range(n_res_block):\n",
    "            blocks.append(ResBlock(channel, n_res_channel))\n",
    "\n",
    "        blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        if stride == 4:\n",
    "            blocks.extend(\n",
    "                [\n",
    "                    nn.ConvTranspose2d(channel, channel // 2, 4, stride=2, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(\n",
    "                        channel // 2, out_channel, 4, stride=2, padding=1\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif stride == 2:\n",
    "            blocks.append(\n",
    "                nn.ConvTranspose2d(channel, out_channel, 4, stride=2, padding=1)\n",
    "            )\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.blocks(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fuKLLBbkGIX"
   },
   "outputs": [],
   "source": [
    "class Quantize(nn.Module):\n",
    "    def __init__(self, dim, n_embed, decay=0.99, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.n_embed = n_embed\n",
    "        self.decay = decay\n",
    "        self.eps = eps\n",
    "\n",
    "        embed = torch.randn(dim, n_embed)\n",
    "        self.register_buffer('embed', embed)\n",
    "        self.register_buffer('cluster_size', torch.zeros(n_embed))\n",
    "        self.register_buffer('embed_avg', embed.clone())\n",
    "\n",
    "    def forward(self, input):\n",
    "        flatten = input.reshape(-1, self.dim)\n",
    "        dist = (\n",
    "            flatten.pow(2).sum(1, keepdim=True)\n",
    "            - 2 * flatten @ self.embed\n",
    "            + self.embed.pow(2).sum(0, keepdim=True)\n",
    "        )\n",
    "        _, embed_ind = (-dist).max(1)\n",
    "        embed_onehot = F.one_hot(embed_ind, self.n_embed).type(flatten.dtype)\n",
    "        embed_ind = embed_ind.view(*input.shape[:-1])\n",
    "        quantize = self.embed_code(embed_ind)\n",
    "        print(self.cluster_size.shape, quantize.shape)\n",
    "\n",
    "        if self.training:\n",
    "            self.cluster_size.data.mul_(self.decay).add_(\n",
    "                1 - self.decay, embed_onehot.sum(0)\n",
    "            )\n",
    "            embed_sum = flatten.transpose(0, 1) @ embed_onehot\n",
    "            self.embed_avg.data.mul_(self.decay).add_(1 - self.decay, embed_sum)\n",
    "            n = self.cluster_size.sum()\n",
    "            cluster_size = (\n",
    "                (self.cluster_size + self.eps) / (n + self.n_embed * self.eps) * n\n",
    "            )\n",
    "            embed_normalized = self.embed_avg / cluster_size.unsqueeze(0)\n",
    "            self.embed.data.copy_(embed_normalized)\n",
    "\n",
    "        diff = (quantize.detach() - input).pow(2).mean()\n",
    "        quantize = input + (quantize - input).detach()\n",
    "\n",
    "        return quantize, diff, embed_ind\n",
    "\n",
    "    def embed_code(self, embed_id):\n",
    "        return F.embedding(embed_id, self.embed.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5qO-Ph4kVH2"
   },
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=3,\n",
    "        channel=128,\n",
    "        n_res_block=2,\n",
    "        n_res_channel=32,\n",
    "        embed_dim=64,\n",
    "        n_embed=512,\n",
    "        decay=0.99,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_b = Encoder(in_channel, channel, n_res_block, n_res_channel, stride=4)\n",
    "        self.enc_t = Encoder(channel, channel, n_res_block, n_res_channel, stride=2)\n",
    "        self.quantize_conv_t = nn.Conv2d(channel, embed_dim, 1)\n",
    "        self.quantize_t = Quantize(embed_dim, n_embed)\n",
    "        self.dec_t = Decoder(\n",
    "            embed_dim, embed_dim, channel, n_res_block, n_res_channel, stride=2\n",
    "        )\n",
    "        self.quantize_conv_b = nn.Conv2d(embed_dim + channel, embed_dim, 1)\n",
    "        self.quantize_b = Quantize(embed_dim, n_embed)\n",
    "        self.upsample_t = nn.ConvTranspose2d(\n",
    "            embed_dim, embed_dim, 4, stride=2, padding=1\n",
    "        )\n",
    "        self.dec = Decoder(\n",
    "            embed_dim + embed_dim,\n",
    "            in_channel,\n",
    "            channel,\n",
    "            n_res_block,\n",
    "            n_res_channel,\n",
    "            stride=4,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_t, quant_b, diff, _, _ = self.encode(input)\n",
    "        dec = self.decode(quant_t, quant_b)\n",
    "\n",
    "        return dec, diff\n",
    "\n",
    "    def encode(self, input):\n",
    "        enc_b = self.enc_b(input)\n",
    "        enc_t = self.enc_t(enc_b)\n",
    "        quant_t = self.quantize_conv_t(enc_t).permute(0, 2, 3, 1)\n",
    "        quant_t, diff_t, id_t = self.quantize_t(quant_t)\n",
    "        quant_t = quant_t.permute(0, 3, 1, 2)\n",
    "        diff_t = diff_t.unsqueeze(0)\n",
    "\n",
    "        dec_t = self.dec_t(quant_t)\n",
    "        enc_b = torch.cat([dec_t, enc_b], 1)\n",
    "\n",
    "        quant_b = self.quantize_conv_b(enc_b).permute(0, 2, 3, 1)\n",
    "        quant_b, diff_b, id_b = self.quantize_b(quant_b)\n",
    "        quant_b = quant_b.permute(0, 3, 1, 2)\n",
    "        diff_b = diff_b.unsqueeze(0)\n",
    "        return quant_t, quant_b, diff_t + diff_b, id_t, id_b\n",
    "\n",
    "    def decode(self, quant_t, quant_b):\n",
    "        upsample_t = self.upsample_t(quant_t)\n",
    "        print(quant_t.shape)\n",
    "        quant = torch.cat([upsample_t, quant_b], 1)\n",
    "        dec = self.dec(quant)\n",
    "\n",
    "        return dec\n",
    "\n",
    "    def decode_code(self, code_t, code_b):\n",
    "        quant_t = self.quantize_t.embed_code(code_t)\n",
    "        quant_t = quant_t.permute(0, 3, 1, 2)\n",
    "        quant_b = self.quantize_b.embed_code(code_b)\n",
    "        quant_b = quant_b.permute(0, 3, 1, 2)\n",
    "\n",
    "        dec = self.decode(quant_t, quant_b)\n",
    "\n",
    "        return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64K4v2KhlZoD"
   },
   "outputs": [],
   "source": [
    "def load_model(model, checkpoint, device):\n",
    "    ckpt = torch.load(checkpoint)\n",
    "\n",
    "    \n",
    "    if 'args' in ckpt:\n",
    "        args = ckpt['args']\n",
    "\n",
    "    if model == 'vqvae':\n",
    "        model = VQVAE()\n",
    "        \n",
    "    if 'model' in ckpt:\n",
    "        ckpt = ckpt['model']\n",
    "\n",
    "    model.load_state_dict(ckpt)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sObZaVB7tuRj"
   },
   "outputs": [],
   "source": [
    "channel = 256\n",
    "res_blocks = 4\n",
    "res_channels = 256\n",
    "out_res_blocks = 0\n",
    "cond_res_blocks = 3\n",
    "dropout = 0.1\n",
    "batch = 8\n",
    "temp = 1.0\n",
    "filename = '/content/image.jpg'\n",
    "vqvae_path = '/content/vqvae_560.pt'\n",
    "inp_path = '/content/trees.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5m53jJQNltFG"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "inp = transform(io.imread(inp_path))\n",
    "print(inp.shape)\n",
    "\n",
    "model_vqvae = load_model('vqvae', vqvae_path, device)\n",
    "decoded_sample, diff = model_vqvae(inp.cuda().unsqueeze(0))\n",
    "decoded_sample = decoded_sample.clamp(-1, 1)\n",
    "\n",
    "print(decoded_sample.shape, diff)\n",
    "\n",
    "save_image(decoded_sample, filename, normalize=True, range=(-1, 1))\n",
    "save_image(inp, '/content/input.jpg', normalize=True, range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXvt_g7U59Y3"
   },
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "VQ-VAE 2.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
